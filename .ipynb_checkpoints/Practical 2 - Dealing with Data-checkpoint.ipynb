{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Python/Pandas\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this session we're going to move swiftly on from our generic introduction to programming covered last time. By the end of the session, we will have used python to do something genuinely useful -- we will:\n",
    "\n",
    "- (a) generate a 'day of year climatology' for air temperature at the HIAL weather station\n",
    "- (b) evaluate the frequency of freezing conditions\n",
    "- (c) compute the positive-degree-day sum(s)\n",
    "\n",
    "To achieve the aim indicated above, we will make use of python $\\it{modules}$. These are libraries of code -- written by others -- which we can use to do sophisticated analysis. Use of modules speeds up our work by several orders of magnitude, and enables us to build on the collective skill of tens of thousands of programmers. \n",
    "\n",
    "Today, we will mainly be using the \"pandas\" module, which was created with data scientists in mind. Pandas enables us to use syntax that is far more intuitive than often encountered elsewhere, and it comes loaded with lots of super-helpful functions. We will only scratch the surface of pandas today, but will return to it in later sessions. \n",
    "\n",
    "We load the pandas module like this (note: please run code like this as you move through the notebook): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the generic syntax -- \"import x as y\". This means, basically, 'load' the module x, but let me refer to it as y. We do this because we will access attributes of the module using its name and the \".\" notation, and it is laborious (and prone to error) if we have to type out the full name of the moudle each time we want to access one of its attributes -- so we use shorthand wherever possible. \n",
    "\n",
    "We are also going to import some other modules needed for today's session: \n",
    "\n",
    "- Matplotlib (https://matplotlib.org/) -- used for making plots/graphs\n",
    "- Numpy (https://numpy.org/) -- used for numerical computation in python\n",
    "- Sklearn (https://scikit-learn.org/stable/) -- used for 'machine learning'\n",
    "\n",
    "Of these, matplotlib and numpy are modules you will use exceptionally often if continuing to learn python after this course. Sklearn brings the dark art of \"machine learning\" -- an application of \"artifical intelligence\" -- to python. We will use if for something far more mundane/familiar today! \n",
    "\n",
    "Run the code below to load the modules. Also note that I have defined a function for you in here (called 'seas_cycle') -- it uses methods from the numpy and sklearn to help 'model' the seasonal cycle of a variable (like air temperature). You will use this later, but don't need to understand all the individual bits of code now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the 'import' statements\n",
    "# --------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt # note that here I do something subtly \n",
    "# different - I import an attribute of matplotlib -- called 'pyplot'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model # this is a little different again, \n",
    "# I'm only importing one attribute (linear_model) from sklearn. \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Below is the code where I define a function for us to use. You do not need\n",
    "# to understand this yet.\n",
    "# --------------------------------------------------------------------------\n",
    "def seas_cycle(ind,n,indata):\n",
    "    y=indata.values[:]\n",
    "    reg = linear_model.LinearRegression() \n",
    "    ind = 2*np.pi*(ind/np.float(n)) \n",
    "    idx = ~np.isnan(y)\n",
    "    X = np.column_stack((np.cos(ind[idx]),np.sin(ind[idx])))\n",
    "    reg.fit(X, y[idx]) \n",
    "    sim = reg.predict(np.column_stack((np.cos(ind),np.sin(ind)))) \n",
    "    return sim\n",
    "# --------------------------------------------------------------------------    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to illustrate the power of Pandas is then by example -- as we work towards our goal of computing a \"climatology\" to make some predictions about the weather. Let's begin by loading data from the HIAL weather station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=\"Data/HIAL_1yr.csv\"\n",
    "data=pd.read_csv(fin,parse_dates=[\"TIMESTAMP\"],index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be clear, I'm accessing the 'method' (or 'function') 'read_csv' that is part of the pandas module. The 'arguments' or 'parameters' I provide to the function are those comma-separated items within the brackets: the first is the $\\it{full}$ filename, the second is a flag that tells pandas that it should try to interpret any dates in the file; and the third is an instruction to tell pandas that the first column of data in the file should be used to index the data -- i.e. which column is the 'axis'. The result of this command is the creation of a new variable called 'data', which is a 'DataFrame' -- a specific type that is available in the pandas module. DataFrames are very clever data types, ideally set up for data analysis. You will see some of these features as we progress through the session. \n",
    "\n",
    "How would $\\it{you}$ figure out what arguments are needed by this method if you didn't have me here to tell you? Easy, you search the help pages. In this case, googling the 'read_csv' method of the pandas module should take you to this page: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Or, alternatively, you can ask python directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, I prefer reading in my browser -- but it's up to you. \n",
    "\n",
    "OK. So back to why we should get excited about pandas and DataFrames...  Below we're goint to print an attribute of data -- 'columns'. This simply outputs a list -- which corresponds to the headings in our csv file. We do this because it's a good check that the data have been read correctly -- and to make sure we refer to the different variables in a way that pandas will understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above should confirm that pandas has understood the structure of your input data. Now, let's immediately do something fun. Let's make a plot of air temperature (which we see is called 'AirTC_Avg'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This first command is needed to make the plots 'appear' in this notebook\n",
    "%matplotlib inline \n",
    "data[\"AirTC_Avg\"].plot(linewidth=0.1,color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How easy was that? And look - pandas has recognised that date (labelled as 'TIMESTAMP') should be used as the x-axis! \n",
    "\n",
    "It's important to digest what we have just done: \n",
    "\n",
    "- indexing: data[\"AirTC_Avg\"] is another, far more intuitive way of 'indexing' an 'iterable' (covered last session) that pandas enables us to use on the DataFrame type  \n",
    "- plotting: the .plot() call is us using the plot method of the data[\"AirTC_Avg\"] variable. There are other ways to make plots in python, but none as straightforward for us -- be glad when your data are in a pandas DataFrame!\n",
    "\n",
    "OK, so that might not seem too impressive; let's do something else to showcase what pandas can do -- and make something more informative to plot at the same time.\n",
    "\n",
    "Below I'm going to use the 'resample' method to, as you may guess, sub-select (or sample) the data. The resample I'm going to perform is to move from 15-min data (the native format), to daily resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_t=data[\"AirTC_Avg\"].resample(\"D\") # Note that the \"D\" indiates \"Daily\".\n",
    "# Even though the code will be new to you, hopefully you find it relatively \n",
    "# intuitive. This readability is a deliberate feature of python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing happened! \n",
    "\n",
    "That's right. All that pandas has done is some work behind the scenes to aggregate the data into daily chunks. But $\\it{how}$ do we want to summarise the data at this lower (daily) resolution -- where we move from 24 x 4 = 96 values/day to just 1? \n",
    "\n",
    "Well, we can choose, by applying another method to the resampler ('daily_t' is the resampler). Below we compute daily mean, min, and max temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daymean_t=daily_t.mean()\n",
    "daymax_t=daily_t.max()\n",
    "daymin_t=daily_t.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that above I call a method with the parentheses, but there are no arguments included. This is beacause pandas does not need any more information to calculate the mean, max or min -- just the variable itself (in this case, daily_t). \n",
    "\n",
    "daymean_t, daymax_t, and daymin_t are now stand-alone variables containing the daily mean, maximum, and minimum temperature, respectively. To check this, we can plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daymean_t.plot()\n",
    "daymax_t.plot()\n",
    "daymin_t.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the maximum temperature recorded so far at HIAL with the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Record high temperature was: \",daymax_t.max(),\"deg C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how about the min?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Record low temperature was: \",daymin_t.min(),\"deg C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plots, you can, I hope, clearly make out the cyclical nature of the temperatures, with a clear (summer) peaks and (winter) trough. \n",
    "\n",
    "We can summarise this cycle in the form of a sine wave, which will help us visually identify the warmest and coldest months of the year. For those of you unfamiliar with a sine wave, here's the world's briefiest overview of what it is:\n",
    "\n",
    "... A sine wave is the curve that is produced by taking the \"sine\" of an ordered sequence of angles between 0 and 360 degrees (or 2$\\pi$ radians). The \"sine\" of argument $x$, remember, is just the ratio of the 'opposite' (vertical) to 'hypotenuse' sides in a right angle triangle, when the angle between the hypotenuse and adjacent sides of the triangle is equal to $x$...\n",
    "\n",
    "This isn't a trigonmetry lesson, so don't worry if you've forgotten what the sine function does, and you don't understand my explanation above. We can instead just think of a sine wave as a function that creates a periodic (repeating)'wave' form.\n",
    "\n",
    "In the below, I demonstrate a sine wave, creating a sequence of numbers to represent the angles 0-360 (using the 'arange' method of numpy); I then feed this to the sine method of numpy (called 'sin') and plot the result for you to see what it looks like. Don't be confused by the 'radians' command -- this just converts the angles into the form that numpy expects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles=np.radians(np.arange(0,361)) # creates the reference series\n",
    "y=np.sin(angles) # use the sin function\n",
    "plt.plot(y) # this is another way to plot something when it isn't a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice shape, right? This has the smooth undulations just as we wanted them. However, how do we get the 'height' (amplitude) to be correct, and how do we make sure that the peak is positioned in summer and the trough in winter (i.e. that the wave has the correct 'phase'? These are important questions, but beyond the scope of our session, so I have written a function for you (the 'seas_cycle' function) to do this. Essentially, it tries to make the curve fit *all* of the data as closely as possible -- i.e passing as closely as possible to all observed temperatures. \n",
    "\n",
    "Run the code below to fit a sine wave to our data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim=seas_cycle(doy.astype(np.float),365.25,daymean_t) # **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. So we are now in a position to visually compare the sine wave to the observations. In the code below we will create a new pandas DataFrame, inserting the observations and the winde wave, before making a plot using the convenient .plot() method of a DataFrame. Note that here I do plot a little differently this time -- creating a blank figure and pair of axes and then plotting on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pd.DataFrame(data={\"obs\":daymean_t.values[:],\"clim\":clim},\\\n",
    "                 index=daymean_t.index) # ** creating a DataFrame\n",
    "fig,ax=plt.subplots(1,1) # blank figure/axes to plot on\n",
    "out.plot(ax=ax) # normal call to plot -- but specifying 'ax' to plot on\n",
    "ax.set_ylabel(\"Air temperature (deg C)\") # cosmetics -- label y-axis\n",
    "ax.set_xlabel(\"Date\") # cosmetics -- label x-axis\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! This addresses aim [a] of the practical. \n",
    "\n",
    "We will come back to this sine wave soon. Fist, though, we are going to address [b] and [c] -- computing the frequency of freezing conditions, and evaluating the degree day sums.\n",
    "\n",
    "Run the code below to evaluate the freqeuncy (percent) of the time with freezing air temperatures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfreeze=(data[\"AirTC_Avg\"]<=0).sum()/data[\"AirTC_Avg\"].count()*100. \n",
    "print(\"Freezing conditions occur about %.0f%% of the time\"%pfreeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the lecture that the positive degree-day sum (PDD) can be used as an indicator of melt energy, and that we can compute it by adding up all air temperatures above zero, and then dividing by the number of observations per day (which for us means dividing by 24 x 4, because our data are recorded at 15-minute resolution). Run the code below we evaluate the PDD sum for HIAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd=data[\"AirTC_Avg\"].loc[data[\"AirTC_Avg\"]>0].sum()/(24*4.)\n",
    "print(\"The PDD sum for HIAL is %.0f C\"%pdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That has now given us answers for [b] and [c] at the annual scale, but let's see how things change when we repeat the assessment at monthly resolution. The code below will compute both the freezing frequency and PDD sum for the respective months -- printing the answer to screen each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1,13): # Here we iterate by allowing m to take on values in the range 1-12\n",
    "    sub_selection=data.loc[data.index.month==m] # create a subset of data for month m\n",
    "    # Below is the same code as above, but this time we apply to the monthly data\n",
    "    pfreeze=(sub_selection[\"AirTC_Avg\"]<=0).sum()/sub_selection[\"AirTC_Avg\"].count()*100\n",
    "    pdd=sub_selection[\"AirTC_Avg\"].loc[sub_selection[\"AirTC_Avg\"]>0].sum()/(24*4.)\n",
    "    \n",
    "    # Update by printing to screen\n",
    "    print(\"Month %.0f...\"%m)\n",
    "    print(\"...Freezing frequency = %.1f%%\"%pfreeze)\n",
    "    print(\"...PDD sum = %.1f C\"%pdd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To be completed\n",
    "\n",
    "- [1] Edit the code segments above so that you can compute the day of year climatology (sine wave) for the daily min and daily maximum temperatures. [Hint: this is not as tricky as it seems -- look for bits of code with # ** -- these are the only bits you need to edit]\n",
    "\n",
    "\n",
    "- [2] Use the output (.csv files) to estimate:\n",
    "\n",
    "\n",
    "    - the date most likely to record the annual maximum temperature \n",
    "    - the date most likely to record the annual minimum temperature\n",
    "    - the mean temperature on the day of our next practical (Monday)\n",
    "    \n",
    "\n",
    "- [3] Write a few short sentences describing the seasonal cycle of mean, minimum, and maximum temperatures at HIAL in Ladakh.\n",
    "\n",
    "\n",
    "- [4] In which month do you think warming would cause the largest **change** in the frequency of freezing conditions?\n",
    "\n",
    "\n",
    "- [5] In which month do you think warming would cause the smallest **change** in the PDD sum?\n",
    "\n",
    "\n",
    "- [6] Can you suggest an approach to check your answers to [4] and [5]? (If so -- try it!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
